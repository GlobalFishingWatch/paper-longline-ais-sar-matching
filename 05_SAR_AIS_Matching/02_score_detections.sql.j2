#StandardSql
# Score extrapolated AIS Postitions. This table uses the output of 01_extrapolate_ais as an input, and produces a table that:
#   1) Serves as in input to 03_rank_detections query
#   2) Joins extrapolated positions to vessel classes, probability rasters, and detections,
#   3) Applies a score for detections to vessels

# CREATE TEMP FUNCTION start_date() AS (DATE_SUB(DATE(''),INTERVAL 1 DAY ));
# CREATE TEMP FUNCTION end_date() AS (DATE_ADD(DATE(''), INTERVAL 1 DAY));
CREATE TEMP FUNCTION YYYYMMDD(d DATE) AS (
  # Format a date as YYYYMMDD
  # e.g. DATE('2018-01-01') => '20180101'
  FORMAT_DATE('%Y%m%d',
    d) );

CREATE TEMP FUNCTION bilinear_interpolation(Q11 float64,
Q12 float64, Q22 float64, Q21 float64, x1 float64, x2 float64,
y1 float64, y2 float64, x float64, y float64) AS (
    # see https://en.wikipedia.org/wiki/Bilinear_interpolation
    # Q11 is the value at x1, y1, Q12 is the value at x1, y2, etc.
    # x and y are the coordinates we want the value for
    1/( (x2 - x1) * (y2 - y1)) *
      (
         Q11 * (x2 - x) * (y2 - y)
       + Q21 * (x - x1) * (y2 - y)
       + Q12 * (x2 - x) * (y - y1)
       + Q22 * (x - x1) * (y - y1)
      )
    );

create temp function colmax(x float64, y float64) as (
  if(x > y, x, y)
);

create temp function radians(x float64) as (
  3.14159265359 * x / 180
);

create temp function deglat2km() as (
  111.699
);

create temp function kilometers_per_nautical_mile() as (
  1.852
);

create temp function map_label(label string)
as (
  case when label ="drifting_longlines" then "drifting_longlines"
  when label ="purse_seines" then "purse_seines"
  when label ="other_purse_seines" then "purse_seines"
  when label ="tuna_purse_seines" then "purse_seines"
  when label ="cargo_or_tanker" then "cargo_or_tanker"
  when label ="cargo" then "cargo_or_tanker"
  when label ="tanker" then "cargo_or_tanker"
  when label ="tug" then "tug"
  when label = "trawlers" then "trawlers"
  else "other" end
);

create temp function map_speed(x float64) as (
  case
  when x < 2 then 0
  when x < 4 then 2
  when x < 6 then 4
  when x < 8 then 6
  when x < 10 then 8
  else 10 end
);

create temp function map_minutes(x float64) as (
  case when x < -384 then  -512
  when x < -256 then -384
  when x < -192 then -256
  when x < -128 then -192
  when x < -96 then -128
  when x < -64 then -96
  when x < -48 then -64
  when x < -32 then -48
  when x < -24 then -32
  when x < -16 then -24
  when x < -12 then -16
  when x < -8 then -12
  when x < -6 then -8
  when x < -4 then -6
  when x < -3 then -4
  when x < -2 then -3
  when x < -1 then -2
  when x < 0 then -1
  when x < 1 then 0
  when x < 2 then 1
  when x < 3 then 2
  when x < 4 then 3
  when x < 6 then 4
  when x < 8 then 6
  when x < 12 then 8
  when x < 16 then 12
  when x < 24 then 16
  when x < 32 then 24
  when x < 48 then 32
  when x < 64 then 48
  when x < 96 then 64
  when x < 128 then 96
  when x < 192 then 128
  when x < 256 then 192
  when x < 384 then 256
  else 384 end);

CREATE TEMP FUNCTION reasonable_lon(lon float64) AS
  (case when lon > 180 then lon - 360
  when lon < -180 then lon + 360
  else lon end
);

CREATE TEMP FUNCTION earth_radius_km(lat float64) as
-- This is super overkill. You could just use the average
-- radius of the earth. But I wanted to see if it made a difference.
-- It matters if you want > 4 significant digits.
-- But, once I made it, I didn't feel like deleting it.
-- Equation taken from https://rechneronline.de/earth-radius/
((
select
  --  R = √ [ (r1² * cos(B))² + (r2² * sin(B))² ] / [ (r1 * cos(B))² + (r2 * sin(B))² ]
  pow(
  ( pow(r1*r1 * cos(B),2) + pow(r2*r2 * sin(B),2) )
  /
  ( pow(r1 * cos(B),2) + pow(r2 * sin(B), 2) )
  ,.5)
    from
    (select
    6371.001 as r1,
    6356.752 as r2,
    Radians(lat) as B)
    limit 1
));

with
######################################
-- Data sources
######################################
--
-- vessel_extrapolated_positions
-- This is a table created through a previous query that gets the extrapolated position
-- of vessels that could be within a given scene. It also includes offset for doppler effect
-- that accounts for satellite direction and speed relative to the vessel

vessel_extrapolated_positions as
 (select * from {{extrapolated_table}}),

-- sar detections
sar_detections as (
SELECT TIMESTAMP_ADD(ProductStartTime, INTERVAL cast(timestamp_diff(ProductStopTime, ProductStartTime, SECOND)/2 as int64) SECOND) detect_timestamp,
 DetectionId as detect_id,
 lon detect_lon,
 lat detect_lat,
 scene_id
 FROM
  {{ detections_table }}
 ),

-- raster probability. "mirror_nozeroes" means that all rows with zero values
-- have been removed, and negative i values have been removed (the raster is
-- symetrical around the i axis because a vessel is just as likely to turn left
-- as it is to turn right).
prob_raster as (select * from
 `world-fishing-827.gfw_research_precursors.point_cloud_mirror_nozeroes_contour_v20190502`
 ),

-- vessel info table, used for vessel class.
-- acceptable vessel classes are "trawlers","purse_seines","tug","cargo_or_tanker","drifting_longlines","fishing", and "other"
vessel_info_table as ({{ vessel_info_table }}),


##################################
# Probability raster adjustments
##################################

-- get the average for general fishing. This is creating a composite category
-- of other categories.
probability_table as (select
   probability,labels,minutes_lower,speed_lower,i,j
from
  prob_raster
union all
select
   avg(probability) probability,"fishing" labels, minutes_lower, speed_lower,i,j
from
  prob_raster
where labels in ("trawlers","purse_seines","drifting_longlines")
group by
   labels,minutes_lower,speed_lower,i,j),

-- weight is a measure of how concetrated the raster is, and is used to assess score
weights as (
select
  # this is because the value at 0 is not mirrored
  sum(if(i>0, 2*probability * probability, probability * probability )) as weight,
  labels,
  minutes_lower,
  speed_lower
from
  probability_table
group by
  labels,
  minutes_lower,
  speed_lower
),

-- combine probabilities and weights into one table
probabilities_and_weights as (
select * from
  probability_table
join
  weights
using(labels, minutes_lower,speed_lower)
),

-- the raster has only positive i values because it is symmetrical
-- around the i axis (the boat is as equally likely to turn left as right).
-- Make a full raster with negative values for the later join.
probabilities_and_weights_neg as (
select
labels, minutes_lower, speed_lower, probability, i, j, weight
from
probabilities_and_weights
union all
select
-- same except take negative i!
labels, minutes_lower, speed_lower, probability, -i as i, j, weight
from
probabilities_and_weights
where i >0
),

extrapolated_unstacked as (
select
scene_id,
scene_timestamp,
ssvid,
timestamp1 as timestamp,
lat1 + lat_doppler_offset1 as lat,
lon1 + lon_doppler_offset1 as lon,
delta_minutes1 as delta_minutes,
speed1 as speed,
scale1 as scale,
course1 as course,
min_lon,
min_lat,
max_lon,
max_lat,
is_single
from vessel_extrapolated_positions
where lat_extrapolate1 is not null
union all
select
scene_id,
scene_timestamp,
ssvid,
timestamp2 as timestamp,
lat2 + lat_doppler_offset2 as lat,
lon2 + lon_doppler_offset2 as lon,
delta_minutes2 as delta_minutes,
speed2 as speed,
scale2 as scale,
course2 as course,
min_lon,
min_lat,
max_lon,
max_lat,
is_single
from vessel_extrapolated_positions
where lat_extrapolate2 is not null
),

# Add vessel class
extrapolated_unstacked_w_label as (
    select * from extrapolated_unstacked
    join vessel_info_table using(ssvid) #switch back to vessel_info_table after walmart dark targets study
),

detects_vs_extrapolated as (
select
ssvid,
label,
scene_id,
detect_id,
detect_lat,
detect_lon,
lat,
lon,
timestamp,
delta_minutes,
speed,
scale,
course,
is_single
from extrapolated_unstacked_w_label
join
 sar_detections
 using(scene_id)
where detect_lat between min_lat and max_lat
and detect_lon between min_lon and max_lon
),

####################
# joins to the probability raster
###################
--
key_query_1 as (
select *,
  deglat2km() * (detect_lon - lon) * cos(radians(lat)) as u,
  deglat2km() * (detect_lat - lat) as v,
  radians(course) as course_rads
from
  detects_vs_extrapolated
),

-- rotate the coordinates
key_query_2 as (
select
  *,
  cos(course_rads) * u - sin(course_rads) * v as x,
  cos(course_rads) * v + sin(course_rads) * u as y
  -- rotation of coordinates, described here: https://en.wikipedia.org/wiki/Rotation_of_axes
  -- Note that our u and v / x and y are switched from the standard way to measure
  -- this, largely because vessels measure course from due north, moving clockwise,
  -- while mosth math measures angle from the x axis counterclockwise. Annoying!
  --
#   1000 / colmax(1.0, ABS(delta_minutes)) as scale
#     This is the python function we are copying here:
#      def scale(dt):
#         return 1000.0 / max(1, abs(dt))
from
  key_query_1
),

-- adjust by scale -- that is the probability raster will be scalled
-- based on how long before or after the ping the image was taken.
-- Also, move the raster so that 0,0 is where the vessel would be
-- if it traveled in a straight line.
key_query_3 as
(
select * from (
  select *,
    x * scale as x_key,
    (y - speed*kilometers_per_nautical_mile()*delta_minutes/60 ) * scale  as y_key, -- the old version extrapolated, and this one doesn't
    # y * scale as y_key,
    # Map these values to the values in the probability rasters
    map_speed(speed) as speed_key,
    map_minutes(delta_minutes) as minute_key,
    map_label(label) as label_key
  from
    key_query_2
  )
where abs(x_key) <=500 and abs(y_key) <=500
),

-- Match to probability, and interpolate between
-- the four closest values. This bilinear interpoloation
-- in theory allows us to reduce the size of the raster we are joining on
messages_with_probabilities as
(
select
  -- this would get the value exact, the weight_scaled
  -- / pow((1000/(colmax( 1, probs.minutes_lower/2 + probs.minutes_upper /2))),2) * scale*scale
  * except(i, j, probability),
  bilinear_interpolation(
  ifnull(probs_11.probability,0),
  ifnull(probs_12.probability,0),
  ifnull(probs_22.probability,0),
  ifnull(probs_21.probability,0),
  cast(x_key - .5 as int64), cast(x_key + .5 as int64),
  cast(y_key - .5 as int64), cast(y_key + .5 as int64) ,
  x_key, y_key) as probability,
  -- to get at least one value.
  -- weight *should* be the same for each, but we need to make sure it isn't null
  case when probs_11.weight is not null then probs_11.weight/(scale*scale)
  when probs_12.weight is not null then probs_12.weight/(scale*scale)
  when probs_22.weight is not null then probs_22.weight/(scale*scale)
  when probs_21.weight is not null then probs_21.weight/(scale*scale)
  else 0
  end
  as weight_scaled
from
  key_query_3
left join
  --
  -- joining on four locaitons to do bilinear interpolation
probabilities_and_weights_neg  as probs_11
  on  probs_11.i = cast(x_key - .5 as int64) and probs_11.j = cast(y_key - .5 as int64)
  and probs_11.speed_lower = cast(speed_key as int64)
  and probs_11.minutes_lower = cast(minute_key as int64)
  and probs_11.labels = label_key
left join
probabilities_and_weights_neg  as probs_12
  on  probs_12.i = cast(x_key -.5 as int64) and probs_12.j = cast(y_key + .5 as int64)
  and probs_12.speed_lower = cast(speed_key as int64)
  and probs_12.minutes_lower = cast(minute_key as int64)
  and probs_12.labels = label_key
left join
probabilities_and_weights_neg  as probs_22
  on  probs_22.i = cast(x_key +.5 as int64) and probs_22.j = cast(y_key + .5 as int64)
  and probs_22.speed_lower = cast(speed_key as int64)
  and probs_22.minutes_lower = cast(minute_key as int64)
  and probs_22.labels = label_key
left join
probabilities_and_weights_neg  as probs_21
  on  probs_21.i = cast(x_key +.5 as int64) and probs_21.j = cast(y_key - .5 as int64)
  and probs_21.speed_lower = cast(speed_key as int64)
  and probs_21.minutes_lower = cast(minute_key as int64)
  and probs_21.labels = label_key
),

joined_back_with_extrapolated_positions as (
  select
  ssvid,
  scene_id,
  ifnull(probability,0) probability,
  ifnull(weight_scaled, 0) weight_scaled,
  a.scale,
  detect_id,
  detect_lon,
  detect_lat,
  scene_timestamp as detect_timestamp,
  a.timestamp,
  a.course,
  a.lat,
  a.lon,
  a.speed,
  a.is_single,
  delta_minutes
  from
  extrapolated_unstacked a
  left join
  messages_with_probabilities b
  using(ssvid, scene_id, delta_minutes)
),

joined_detects AS (
SELECT
  ssvid,
  "AIS" as source,
  scene_id scene_id,
  detect_id detect_id,
  ifnull(a.detect_timestamp, b.detect_timestamp) detect_timestamp,
  detect_lat,
  detect_lon,
  if(a.probability is null, 0, a.probability ) probability1,
  if(b.probability is null, 0, b.probability ) probability2,
  if(a.weight_scaled is null, 0, a.weight_scaled ) weight_scaled1,
  if(b.weight_scaled is null, 0, b.weight_scaled ) weight_scaled2,
  a.scale scale1,
  b.scale scale2

FROM
  (select * from  joined_back_with_extrapolated_positions where delta_minutes >= 0) a
full outer join
  (select * from joined_back_with_extrapolated_positions where delta_minutes < 0) b
using(ssvid, detect_id, scene_id, detect_lat, detect_lon)
-- following line should eliminate where one score is null
where ifnull(a.is_single, b.is_single) or (ifnull(a.probability,0) > 0 and ifnull(b.probability,0) > 0)
),

-- Apply a score to each detection to vessel
-- This score was figured out by Tim Hochberg, who tried
-- out a series of different things.

scored_detects as (
select *,
  safe_divide( (probability1 * weight_scaled1 +
   probability2 * weight_scaled2),
weight_scaled1 + weight_scaled2) AS score
from joined_detects)


-- scored_detects as (
-- select * except (probability),
-- if(a.ssvid = b.ssvid and
--   a.scene_id = b.scene_id and
--   a.detect_id = b.detect_id, b.probability, safe_divide( (probability1 * weight_scaled1 +
--     probability2 * weight_scaled2),
-- weight_scaled1 + weight_scaled2)) AS score
-- from joined_detects a
-- left join scratch_david.probability_mult_streamline_v20200414 b
-- using(ssvid, scene_id, detect_id))


# #################################################
# # And the answer is....
# #################################################
# --

select * from scored_detects where score > 0
